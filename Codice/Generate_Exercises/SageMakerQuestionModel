from sagemaker.huggingface import HuggingFaceModel
from sagemaker import get_execution_role
import sagemaker

hub = {
    'HF_MODEL_ID': 'valhalla/t5-base-e2e-qg',
    'HF_TASK': 'text2text-generation'
}

qg_model = HuggingFaceModel(
    transformers_version='4.26',
    pytorch_version='1.13',
    py_version='py39',
    env=hub,
    role=role
)

qg_predictor = qg_model.deploy(
    initial_instance_count=1,
    instance_type='ml.m5.large',
    endpoint_name='QG-E2E'
)
